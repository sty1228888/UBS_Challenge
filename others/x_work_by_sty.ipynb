{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the dataset ... DONE\n"
     ]
    }
   ],
   "source": [
    "import os, sys; sys.path.insert(0, os.path.join(sys.path[0], '..'))\n",
    "import pandas as pd\n",
    "\n",
    "print (f\"Read the dataset ... \", end = \"\")\n",
    "try: data_transformed = pd.read_csv(os.path.join(\"..\", \"assets\", \"final_ubs_data.csv\"))\n",
    "except: data_transformed = pd.read_csv(os.path.join(\"assets\", \"final_ubs_data.csv\"))\n",
    "columns = data_transformed.columns\n",
    "columns_filtered = [column for column in columns if column != \"Mean_Vega\"]\n",
    "data = data_transformed[columns_filtered]  # Convert the transformed file to the merged file\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Value Date</th>\n",
       "      <th>Trade Name</th>\n",
       "      <th>Trade Currency</th>\n",
       "      <th>Zero Rate Shock</th>\n",
       "      <th>TV</th>\n",
       "      <th>Expiry Bucket</th>\n",
       "      <th>Expiry Date</th>\n",
       "      <th>Tenor Bucket</th>\n",
       "      <th>Vega</th>\n",
       "      <th>...</th>\n",
       "      <th>atm-0.5%</th>\n",
       "      <th>atm</th>\n",
       "      <th>atm+0.5%</th>\n",
       "      <th>atm+1.0%</th>\n",
       "      <th>Swap Rate</th>\n",
       "      <th>underlying</th>\n",
       "      <th>pay_frequency</th>\n",
       "      <th>maturity</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>dummyTrade1</td>\n",
       "      <td>USD</td>\n",
       "      <td>-100</td>\n",
       "      <td>-227907.098775</td>\n",
       "      <td>1y</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>10y</td>\n",
       "      <td>1.962246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.177525</td>\n",
       "      <td>0.21682</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>2.737709</td>\n",
       "      <td>USD: CMS:2Y</td>\n",
       "      <td>6M</td>\n",
       "      <td>5Y</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>dummyTrade1</td>\n",
       "      <td>USD</td>\n",
       "      <td>-50</td>\n",
       "      <td>-222208.400967</td>\n",
       "      <td>1y</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>10y</td>\n",
       "      <td>-3.812341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.177525</td>\n",
       "      <td>0.21682</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>2.737709</td>\n",
       "      <td>USD: CMS:2Y</td>\n",
       "      <td>6M</td>\n",
       "      <td>5Y</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>dummyTrade1</td>\n",
       "      <td>USD</td>\n",
       "      <td>-25</td>\n",
       "      <td>-218960.927995</td>\n",
       "      <td>1y</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>10y</td>\n",
       "      <td>4.471006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.177525</td>\n",
       "      <td>0.21682</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>2.737709</td>\n",
       "      <td>USD: CMS:2Y</td>\n",
       "      <td>6M</td>\n",
       "      <td>5Y</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>dummyTrade1</td>\n",
       "      <td>USD</td>\n",
       "      <td>-10</td>\n",
       "      <td>-216872.430106</td>\n",
       "      <td>1y</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>10y</td>\n",
       "      <td>4.333398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.177525</td>\n",
       "      <td>0.21682</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>2.737709</td>\n",
       "      <td>USD: CMS:2Y</td>\n",
       "      <td>6M</td>\n",
       "      <td>5Y</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>dummyTrade1</td>\n",
       "      <td>USD</td>\n",
       "      <td>-5</td>\n",
       "      <td>-216146.310328</td>\n",
       "      <td>1y</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>10y</td>\n",
       "      <td>5.679687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.177525</td>\n",
       "      <td>0.21682</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>2.737709</td>\n",
       "      <td>USD: CMS:2Y</td>\n",
       "      <td>6M</td>\n",
       "      <td>5Y</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Value Date   Trade Name Trade Currency  Zero Rate Shock  \\\n",
       "0           1  2022-09-02  dummyTrade1            USD             -100   \n",
       "1           2  2022-09-02  dummyTrade1            USD              -50   \n",
       "2           3  2022-09-02  dummyTrade1            USD              -25   \n",
       "3           4  2022-09-02  dummyTrade1            USD              -10   \n",
       "4           5  2022-09-02  dummyTrade1            USD               -5   \n",
       "\n",
       "              TV Expiry Bucket Expiry Date Tenor Bucket      Vega  ...  \\\n",
       "0 -227907.098775            1y  2023-09-04          10y  1.962246  ...   \n",
       "1 -222208.400967            1y  2023-09-04          10y -3.812341  ...   \n",
       "2 -218960.927995            1y  2023-09-04          10y  4.471006  ...   \n",
       "3 -216872.430106            1y  2023-09-04          10y  4.333398  ...   \n",
       "4 -216146.310328            1y  2023-09-04          10y  5.679687  ...   \n",
       "\n",
       "   atm-0.5%       atm  atm+0.5%  atm+1.0%  Swap Rate   underlying  \\\n",
       "0  0.209405  0.177525   0.21682  0.274552   2.737709  USD: CMS:2Y   \n",
       "1  0.209405  0.177525   0.21682  0.274552   2.737709  USD: CMS:2Y   \n",
       "2  0.209405  0.177525   0.21682  0.274552   2.737709  USD: CMS:2Y   \n",
       "3  0.209405  0.177525   0.21682  0.274552   2.737709  USD: CMS:2Y   \n",
       "4  0.209405  0.177525   0.21682  0.274552   2.737709  USD: CMS:2Y   \n",
       "\n",
       "  pay_frequency maturity lower_bound  upper_bound  \n",
       "0            6M       5Y      0.0042       0.0379  \n",
       "1            6M       5Y      0.0042       0.0379  \n",
       "2            6M       5Y      0.0042       0.0379  \n",
       "3            6M       5Y      0.0042       0.0379  \n",
       "4            6M       5Y      0.0042       0.0379  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib --quiet\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost --quiet\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn --quiet  # sklearn is depreciated\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# The training method\n",
    "tree_method = 'cpu_hist'  # 'gpu_hist'\n",
    "\n",
    "# The callback for each epoch to show the progress\n",
    "class InformEpochCallback(xgb.callback.TrainingCallback):\n",
    "    def __init__(self, print_every=1):\n",
    "        self.print_every = print_every\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        if (epoch + 1) % self.print_every == 0:\n",
    "            print(f\"Epoch: {epoch + 1}, Train loss: {evals_log['train'][0][1]}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Value Model: Set 1\n",
    "\n",
    "Independent columns include: \n",
    "\n",
    "- ```Trade Name```\n",
    "\n",
    "- ```Zero Rate Shock (ZRS)```\n",
    "\n",
    "- ```Expiry Bucket```\n",
    "\n",
    "- ```Tenor Bucket```\n",
    "\n",
    "- ```atm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process the data ... DONE\n",
      "Splitting the data ... DONE\n",
      "Constructing training set ... "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "\n",
    "print (\"Process the data ... \", end = \"\")\n",
    "\n",
    "# Select columns\n",
    "selected_columns = ['Value Date', 'Trade Name', 'Zero Rate Shock', 'TV', 'Expiry Bucket', 'Tenor Bucket', 'Vega', 'atm']\n",
    "data_selected = data[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numeric using get_dummies\n",
    "data_processed = pd.get_dummies(data_selected, columns=['Trade Name', 'Expiry Bucket', 'Tenor Bucket', 'Value Date'])\n",
    "\n",
    "# Define the feature set (X) and target variable (y)\n",
    "X = data_processed.drop('TV', axis=1)  # Drop the target column to create the feature set\n",
    "y = data_processed['TV']               # Target variable\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "# Split data into train and test sets (60% train, 40% test)\n",
    "print (\"Splitting the data ... \", end = \"\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)  # random_state for reproducibility\n",
    "print (\"DONE\")\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "print (\"Constructing training set ... \", end = \"\")\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "print (\"DONE\")\n",
    "print (\"Constructing testing set ... \", end = \"\")\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "print (\"DONE\")\n",
    "\n",
    "# Set parameters for XGBoost\n",
    "params = {\n",
    "     'tree_method': 'gpu_hist', \n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 1  # 100\n",
    "print (\"Training the model ... \", end = \"\")\n",
    "inform_epoch_callback = InformEpochCallback(print_every=1)\n",
    "bst = xgb.train(params, dtrain, num_rounds, \n",
    "                callbacks = [inform_epoch_callback])\n",
    "print (\"DONE\")\n",
    "\n",
    "# Predictions and evaluate\n",
    "predictions = bst.predict(dtest)\n",
    "rmse = ((predictions - y_test) ** 2).mean() ** 0.5  # Calculating RMSE\n",
    "print(f'RMSE on test set: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select columns\n",
    "selected_columns = ['Value Date', 'Trade Name', 'Zero Rate Shock', 'TV', 'Expiry Bucket', 'Tenor Bucket', 'Vega', 'atm']\n",
    "data_selected = data[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numeric using get_dummies\n",
    "data_processed = pd.get_dummies(data_selected, columns=['Trade Name', 'Expiry Bucket', 'Tenor Bucket', 'Value Date'])\n",
    "\n",
    "# Define the feature set (X) and target variable (y)\n",
    "X = data_processed.drop('TV', axis=1)  # Drop the target column to create the feature set\n",
    "y = data_processed['TV']               # Target variable\n",
    "\n",
    "# Now, plot the distribution of 'TV'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y, bins=50, alpha=0.75)\n",
    "plt.title('Distribution of TV')\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Also, print some statistics\n",
    "print(\"Minimum TV:\", y.min())\n",
    "print(\"Maximum TV:\", y.max())\n",
    "print(\"Mean TV:\", y.mean())\n",
    "print(\"Standard Deviation of TV:\", y.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select columns\n",
    "selected_columns = ['Value Date', 'Trade Name', 'Zero Rate Shock', 'TV', 'Expiry Bucket', 'Tenor Bucket', 'Vega', 'atm-1.0%', 'atm-0.5%', 'atm', 'atm+0.5%', \n",
    "                    'atm+1.0%', 'Swap Rate', 'pay_frequency', 'maturity','lower_bound', 'upper_bound']\n",
    "data_selected = data[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numeric using get_dummies\n",
    "data_processed = pd.get_dummies(data_selected, columns=['Trade Name', 'Expiry Bucket', 'Tenor Bucket', 'Value Date','pay_frequency','maturity'])\n",
    "\n",
    "# Define the feature set (X) and target variable (y)\n",
    "X = data_processed.drop('TV', axis=1)  # Features\n",
    "y = data_processed['TV']               # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Configure parameters for XGBoost\n",
    "params = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 200\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = ((predictions - y_test) ** 2).mean() ** 0.5\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "explained_variance = explained_variance_score(y_test, predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Explained Variance Score: {explained_variance}\")\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y_test - predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.title('Residuals vs. Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select columns\n",
    "selected_columns = ['Value Date', 'Trade Name', 'Zero Rate Shock', 'TV', 'Expiry Bucket', 'Tenor Bucket', 'Vega', 'atm-1.0%', 'atm-0.5%', 'atm', 'atm+0.5%', \n",
    "                    'atm+1.0%', 'Swap Rate', 'pay_frequency', 'maturity','lower_bound', 'upper_bound']\n",
    "data_selected = data[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numeric using get_dummies\n",
    "data_processed = pd.get_dummies(data_selected, columns=['Trade Name', 'Expiry Bucket', 'Tenor Bucket', 'Value Date','pay_frequency','maturity'])\n",
    "\n",
    "# Define the feature set (X) and target variable (y)\n",
    "X = data_processed.drop('TV', axis=1)  # Features\n",
    "y = data_processed['TV']               # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Configure parameters for XGBoost\n",
    "params = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 1  # 450\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = ((predictions - y_test) ** 2).mean() ** 0.5\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "explained_variance = explained_variance_score(y_test, predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Explained Variance Score: {explained_variance}\")\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y_test - predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.title('Residuals vs. Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select columns\n",
    "selected_columns = ['Value Date', 'Trade Name', 'Zero Rate Shock', 'TV', 'Expiry Bucket', 'Tenor Bucket', 'Vega', 'atm-1.0%', 'atm-0.5%', 'atm', 'atm+0.5%', \n",
    "                    'atm+1.0%', 'Swap Rate', 'pay_frequency', 'maturity','lower_bound', 'upper_bound']\n",
    "data_selected = data[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numeric using get_dummies\n",
    "data_processed = pd.get_dummies(data_selected, columns=['Trade Name', 'Expiry Bucket', 'Tenor Bucket', 'Value Date','pay_frequency','maturity'])\n",
    "\n",
    "# Define the feature set (X) and target variable (y)\n",
    "X = data_processed.drop('Vega', axis=1)  # Assuming you're predicting Vega as before\n",
    "y = data_processed['Vega']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Configure parameters for XGBoost\n",
    "params = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 1  # 200\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Predictions\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = ((predictions - y_test) ** 2).mean() ** 0.5\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "explained_variance = explained_variance_score(y_test, predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Explained Variance Score: {explained_variance}\")\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y_test - predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.title('Residuals vs. Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
